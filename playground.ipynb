{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe96c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#363 vs 361\n",
    "# with and without transition statement\n",
    "# with and without response times\n",
    "# with and without I don't know only.\n",
    "# with random names and with sequential user1, user2, etc...\n",
    "# should include username to demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6dae655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"experiment_data/sqb/sqb_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48e93b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqb_markers = [\"National Highway Safety\", \"You are a serious reader\", \"When evaluating teaching job offers,\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e97c2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Participant:\n",
    "\n",
    "    transcript = \"\"\n",
    "    transcript_with_response_times = \"\"\n",
    "    choice_problem = \"\"\n",
    "\n",
    "    def process_transcript(self, chat_transcript):\n",
    "        # Transcript without response times\n",
    "        transcript = \"\"\n",
    "        for msg in chat_transcript:\n",
    "            if any(marker in msg['content'] for marker in sqb_markers):\n",
    "                break\n",
    "            transcript += f\"{msg['role']}: {msg['content']}\\n\"\n",
    "\n",
    "        # Transcript with response times\n",
    "        transcript_with_response_times = \"\"\n",
    "        for i, msg in enumerate(chat_transcript):\n",
    "\n",
    "            if any(marker in msg['content'] for marker in sqb_markers):\n",
    "                break\n",
    "\n",
    "            time_diff = None\n",
    "\n",
    "            if i > 1:\n",
    "                if msg['timestamp']['client_timestamp'] != 0 and chat_transcript[i-1]['timestamp']['client_timestamp'] != 0:\n",
    "                    time_diff = msg['timestamp']['client_timestamp'] - chat_transcript[i-1]['timestamp']['client_timestamp']\n",
    "                else:\n",
    "                    try:\n",
    "                        time_diff = msg['timestamp']['server_timestamp'] - chat_transcript[i-1]['timestamp']['server_timestamp']\n",
    "                    except KeyError:\n",
    "                        time_diff = -1\n",
    "\n",
    "            # Add a blank line before each message except the first\n",
    "            if i > 0:\n",
    "                transcript_with_response_times += \"\\n\"\n",
    "\n",
    "            if msg['role'] == 'user' and i > 1:\n",
    "                transcript_with_response_times += f\"{msg['role']}: {msg['content']} (response time: {time_diff} ms)\"\n",
    "            else:\n",
    "                transcript_with_response_times += f\"{msg['role']}: {msg['content']}\"\n",
    "\n",
    "        # Extract the choice problem statement\n",
    "        choice_problem = \"\\n\".join(f\"{msg['role']}: {msg['content']}\" for msg in chat_transcript if any(marker in msg['content'] for marker in sqb_markers))\n",
    "        choice_problem = choice_problem.replace(\"assistant: \", \"\")\n",
    "\n",
    "        self.transcript = transcript\n",
    "        self.transcript_with_response_times = transcript_with_response_times\n",
    "        self.choice_problem = choice_problem\n",
    "\n",
    "\n",
    "    def __init__(self, participant_id = None, condition = None, prolific_data = None, chat_transcript = None, change_username = None, change_assistantname = None):\n",
    "        # Unique identifier for the participant\n",
    "        self.Participant_ID = participant_id\n",
    "\n",
    "        # Experiment condition\n",
    "        self.condition = condition\n",
    "\n",
    "        # Demographic info from Prolific\n",
    "        self.prolific_data = prolific_data\n",
    "\n",
    "        # Chat Data\n",
    "        self.chat_transcript = chat_transcript if chat_transcript is not None else []\n",
    "\n",
    "        if self.chat_transcript is not None:\n",
    "            self.process_transcript(self.chat_transcript)\n",
    "\n",
    "        if change_username is not None:\n",
    "            self.change_user_name(change_username)\n",
    "\n",
    "        if change_assistantname is not None:\n",
    "            self.change_assistant_name(change_assistantname)\n",
    "\n",
    "    def update_participant_id(self, participant_id):\n",
    "        self.Participant_ID = participant_id\n",
    "\n",
    "    def update_condition(self, condition):\n",
    "        self.condition = condition\n",
    "\n",
    "    def update_prolific_data(self, key, value):\n",
    "        if self.prolific_data is not None:\n",
    "            self.prolific_data[key] = value\n",
    "\n",
    "    def update_chat_transcript(self, chat_transcript):\n",
    "        self.chat_transcript = self.process_transcript(chat_transcript)\n",
    "\n",
    "    def get_participant_id(self):\n",
    "        return self.Participant_ID\n",
    "\n",
    "    def get_demographics(self):\n",
    "        return self.prolific_data\n",
    "\n",
    "    def get_transcript(self) -> str:\n",
    "        return self.transcript\n",
    "    \n",
    "    def get_transcript_with_response_times(self) -> str:\n",
    "        return self.transcript_with_response_times\n",
    "\n",
    "    def get_choice_problem(self) -> str:\n",
    "        return self.choice_problem\n",
    "    \n",
    "    def change_user_name(self, new_name):\n",
    "        self.transcript = self.transcript.replace(\"user:\", f\"{new_name}:\")\n",
    "        self.transcript_with_response_times = self.transcript_with_response_times.replace(\"user:\", f\"{new_name}:\")\n",
    "    \n",
    "    def change_assistant_name(self, new_name):\n",
    "        self.transcript = self.transcript.replace(\"assistant:\", f\"{new_name}:\")\n",
    "        self.transcript_with_response_times = self.transcript_with_response_times.replace(\"assistant:\", f\"{new_name}:\")\n",
    "\n",
    "columns = [\n",
    "    \"Age\",\n",
    "    \"Sex\",\n",
    "    \"Ethnicity simplified\",\n",
    "    \"Country of birth\",\n",
    "    \"Country of residence\",\n",
    "    \"Nationality\",\n",
    "    \"Language\",\n",
    "    \"Student status\",\n",
    "    \"Employment status\"\n",
    "]\n",
    "\n",
    "participants = []\n",
    "\n",
    "import ast\n",
    "\n",
    "for row_id in range(len(df)):\n",
    "\n",
    "    participant = Participant(participant_id = df[\"Participant id\"][row_id], \n",
    "                            condition = df[\"expcode\"][row_id], \n",
    "                            prolific_data = {col: df.loc[row_id, col] for col in columns}, \n",
    "                            chat_transcript = ast.literal_eval(df[\"chat_data\"][row_id]),\n",
    "                            change_username = \"[User]\",\n",
    "                            change_assistantname = \"[Interviewer]\"\n",
    "                           )\n",
    "    participants.append(participant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a6a0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(participants[0].get_demographics())\n",
    "# print(participants[0].get_transcript())\n",
    "# print(participants[0].get_transcript_with_response_times())\n",
    "# print(participants[0].get_choice_problem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea590b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:16<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from genagents.genagents import GenerativeAgent\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "sim_output = []\n",
    "\n",
    "for participant in tqdm(participants[112:130]):\n",
    "    # Initialize a new agent\n",
    "    agent = GenerativeAgent()\n",
    "    # Update the agent's scratchpad with personal information\n",
    "    agent.update_scratch({k: (v.item() if hasattr(v, \"item\") else v) for k, v in participant.get_demographics().items()})\n",
    "    dialogue = [\n",
    "        (\"Interviewer\", participant.get_choice_problem()),\n",
    "    ]\n",
    "\n",
    "    response = agent.utterance(dialogue, context=participant.get_transcript())\n",
    "\n",
    "    sim_output.append({ participant.get_participant_id() : response })\n",
    "\n",
    "    agent.save(\"experiment_agents/{}\".format(participant.get_participant_id()))\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc62a240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'396d87109b7be13c46a1465cfc85c0a7da98cd7d89dad7b4': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a6ad7459b7eb06919a61557a483c2a789cc9629dddc84e5': 'I would choose to allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a6bd514c17bef6d43f51507a4d193f58ecccb208adfd5e4': 'I would allocate 50% to auto safety and 50% to highway safety.'},\n",
       " {'3a6ed01f9a7ee46614f7135df0d7c6abdc9fca7d8d8d81b5': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3961d316cd7bb73817a44251a682c2a3db9f987a80dd82ef': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'393ddc17cb7de76f10a44106a6d0c1a1dbcccb21d9d385b5': 'I would choose to allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a6ed1439f7ae46a43f24300f2d7cba0d39ccd7dd9dbd4b3': 'I would choose to allocate 50% to auto safety and 50% to highway safety.'},\n",
       " {'3a6ed212c028e16f15a14250f1d3c0a7dc9d9b2989dcd2e2': 'I would allocate 50% to auto safety and 50% to highway safety.'},\n",
       " {'3939dc1ec82eb26616f11750a3dec2a3db9f967edddfd3e1': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a6fdd1fca7bef3844f71207fdd3caa38f99c97c88d8d5b6': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'393cd1159a2ce36816fc1754f2d0c2a3db9f9c7b80d983b1': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a69d416cc2be33d18f31556f5dfc6a18e969b2888df86e6': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a6d8417ce7fb23846a01554a1df90a588cbc92b8fde82b3': 'I would allocate 50% to auto safety and 50% to highway safety.'},\n",
       " {'393bd113cf2eb36d11f44206f484c2a3db9fc97eded8d7b2': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3939861f987cef6b45f4105cfcd1c2a3db9f9979d98ad4e3': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'3a68dd16c028b76f41fd1853f782c1a0df979a7e80d280e3': 'I would allocate 50% to auto safety and 50% to highway safety.'},\n",
       " {'393d861ecf2fe56810fc1154f281c2f2dd999d2b89d385e5': 'I would allocate 60% to auto safety and 40% to highway safety.'},\n",
       " {'39618745c172e23f13a61450a4d6c2a3db9fcc7bdbdfd7e0': 'I would allocate 60% to auto safety and 40% to highway safety.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_output = {}\n",
    "for d in sim_output:\n",
    "    merged_output.update(d)\n",
    "merged_output\n",
    "\n",
    "merged_df = pd.DataFrame(list(merged_output.items()), columns=[\"Participant_ID\", \"Response\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"experiment_data/sqb/sqb_simulated_responses_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786efc8",
   "metadata": {},
   "source": [
    "#### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pid = 112\n",
    "# # pid = 363\n",
    "# pid = 1\n",
    "\n",
    "# from genagents.genagents import GenerativeAgent\n",
    "# import json\n",
    "\n",
    "\n",
    "# agent = GenerativeAgent()\n",
    "\n",
    "# agent.update_scratch({k: (v.item() if hasattr(v, \"item\") else v) for k, v in participants[pid].get_demographics().items()})\n",
    "\n",
    "# dialogue = [\n",
    "#     (\"Interviewer\", participants[pid].get_choice_problem()),\n",
    "# ]\n",
    "\n",
    "# response = agent.utterance(dialogue, context=participants[pid].get_transcript())\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# agent.save(\"experiment_agents/{}\".format(participants[pid].get_participant_id()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b3f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
